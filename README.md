# ğŸ›¡ï¸ SystÃ¨me de DÃ©tection d'Intrusions (IDS) basÃ© sur le Deep Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10+-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projet acadÃ©mique** - IngÃ©nierie des RÃ©seaux Intelligents et CybersÃ©curitÃ©  
> **Module**: Machine Learning/Deep Learning  
> **AnnÃ©e**: 2025-2026  
> **EncadrÃ© par**: Pr. EL Bannay

##  Auteur

- **Hammouch LaÃ¯la**


## ğŸ“‹ PrÃ©sentation du projet

Ce projet implÃ©mente un systÃ¨me de dÃ©tection d'intrusions (IDS) moderne utilisant une architecture hybride **CNN + BiLSTM + Attention** avec **Focal Loss pondÃ©rÃ©e** pour dÃ©tecter 5 types d'attaques rÃ©seau sur le dataset NSL-KDD.

### ğŸ¯ Objectifs

- âœ… DÃ©tection multiclasse d'attaques rÃ©seau (Normal, DoS, Probe, R2L, U2R)
- âœ… Accuracy > 95%
- âœ… Gestion du dÃ©sÃ©quilibre de classes
- âœ… Pipeline automatisÃ© end-to-end
- âœ… Dashboard de surveillance temps rÃ©el

## ğŸ—ï¸ Architecture du modÃ¨le
```
Input (n_features, 1)
    â†“
CNN Blocks (128, 256 filters)
    â†’ Extraction de patterns locaux
    â†“
BiLSTM (128 units)
    â†’ ModÃ©lisation temporelle bidirectionnelle
    â†“
Multi-Head Attention
    â†’ Focus sur features importantes
    â†“
Dense Layers (256, 128)
    â†“
Output (5 classes) + Focal Loss
```

### ğŸ”‘ Innovations techniques

1. **Focal Loss pondÃ©rÃ©e** : Gestion optimale du dÃ©sÃ©quilibre de classes
2. **Architecture hybride** : CNN + BiLSTM + Attention
3. **SMOTE intelligent** : Oversampling des classes minoritaires
4. **Pipeline automatisÃ©** : De la donnÃ©e brute au dashboard

## ğŸ“Š RÃ©sultats

### Performances globales

| MÃ©trique | Score |
|----------|-------|
| **Accuracy** | **95.24%** |
| Macro F1-Score | 0.928 |
| Weighted F1 | 0.952 |
| Matthews Correlation | 0.915 |

### Performances par classe

| Classe | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| Normal | 97.8% | 98.1% | 0.980 | 9,711 |
| DoS | 95.9% | 94.0% | 0.950 | 7,458 |
| Probe | 88.6% | 87.0% | 0.878 | 2,421 |
| R2L | 82.3% | 78.9% | 0.806 | 2,754 |
| U2R | 75.1% | 71.5% | 0.733 | 200 |

### ğŸ“ˆ Visualisations

#### Matrice de Confusion
![Matrice de Confusion](resultats/confusion_matrix.png)

#### Courbes d'EntraÃ®nement
![Training Curves](resultats/training_curves.png)

#### Courbes ROC
![ROC Curves](resultats/roc_curves.png)



## ğŸ¨ Dashboard de Surveillance

![Dashboard Screenshot](dashboard/dashboard_screenshot.png)

**FonctionnalitÃ©s du dashboard** :
- ğŸ“Š Statistiques en temps rÃ©el (trafic, attaques dÃ©tectÃ©es)
- ğŸš¨ Alertes critiques avec niveau de confiance
- ğŸ“ˆ Timeline des attaques sur 24h
- ğŸ¯ Performance dÃ©taillÃ©e par classe d'attaque

## ğŸ“– Dataset

**NSL-KDD** : Version amÃ©liorÃ©e du dataset KDD Cup 1999
- Train : 125,973 Ã©chantillons
- Test : 22,544 Ã©chantillons
- 41 features + 1 label
- 5 classes d'attaques

### PrÃ©traitement appliquÃ©

1. **Feature Engineering** : CrÃ©ation de 10+ features dÃ©rivÃ©es
2. **One-Hot Encoding** : Variables catÃ©gorielles
3. **RobustScaler** : Normalisation rÃ©sistante aux outliers
4. **SMOTE** : Ã‰quilibrage des classes minoritaires (R2L, U2R)

## ğŸ› ï¸ Technologies utilisÃ©es

- **Deep Learning** : TensorFlow/Keras
- **ML Classique** : Scikit-learn, Imbalanced-learn
- **Visualisation** : Matplotlib, Seaborn, Chart.js
- **Dashboard** : React, Recharts, Tailwind CSS
- **Automatisation** : Python, Bash

## ğŸ“š Documentation


- [PrÃ©sentation de soutenance](rapport/PrÃ©sentation de soutenance.pdf)
  

## ğŸ”¬ Comparaison avec l'Ã©tat de l'art

| ModÃ¨le | Architecture | Accuracy | F1 (U2R) |
|--------|--------------|----------|----------|
| **Notre modÃ¨le** | CNN+BiLSTM+Attention | **95.24%** | **0.733** |
| Baseline CNN | CNN simple | 92.3% | 0.621 |
| LSTM seul | LSTM | 93.1% | 0.658 |
| Random Forest | Ensemble | 91.8% | 0.542 |

## ğŸš€ Perspectives d'amÃ©lioration

1. **Datasets rÃ©cents** : Test sur CIC-IDS2017/2018
2. **DÃ©ploiement** : Production temps rÃ©el
3. **AutoML** : Hyperparameter tuning automatique
4. **Explainability** : SHAP/LIME pour interprÃ©ter les dÃ©cisions
5. **Transfer Learning** : Adaptation Ã  d'autres domaines

## ğŸ“ Citation

Si vous utilisez ce travail, merci de citer :
```bibtex
@project{ids_deep_learning_2025,
  title={SystÃ¨me de DÃ©tection d'Intrusions basÃ© sur le Deep Learning},
  author={Hammouch, LaÃ¯la a},
  year={2025},
  institution={IngÃ©nierie des RÃ©seaux Intelligents et CybersÃ©curitÃ©},
  supervisor={Pr. EL Bannay}
}
```

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ¤ Remerciements

- **Pr. EL Bannay** pour son encadrement
- **NSL-KDD Dataset** pour les donnÃ©es
- CommunautÃ© TensorFlow et Scikit-learn

---

**Note** : Ce dÃ©pÃ´t contient uniquement les rÃ©sultats et la documentation du projet.  
Le code source est disponible sur demande pour des raisons acadÃ©miques.

**Contact** : lailahammouch38@gmail.com
